하둡을 사용해서 병렬처리?? -> 빅데이터 분석 문제들에 대해서 맵리듀스 알고리즘을 자바언어로 구현하고 실행한다.

Scale-out 아주 많은 값싼 서버들을 이용함
Scale-up 적은 수의 값비싼 서버들을 이용함

데이터 중심 어플리케이션 분야에서는 아주 많은 값싼 서버들을 많이 이용하는 것을 선호함
고가의 서버들은 가격에 관점에서는 선형으로 성능이 증가하지 않음 -> 두 배의 성능의 프로세서 한 개를 가진 컴퓨터의 가격이 일반적인 프로세서 한 개를 가진 컴퓨터 가격의 두 배보다 훨씬 더 비쌈

맵리듀스 프레임워크는 많은 컴퓨터를 묶어서 처리한다. 병렬처리

데이터 중심 프로세싱

- 한대의 컴퓨터의 능력으로 처리가 어려움
- 근본적으로 수 십대, 수백대 혹은 수 천대의 컴퓨터를 묶어서 처리해야함
- 맵리듀스 프레임 워크가 하는 것이 바로 이것
  맵리듀스는 빅데이터를 이용한 효율적인 계산이 가능한 첫 번째 프로그래밍 모델
  구글의 맵리듀스 또는 오픈소스인 하둡은 맵리듀스 프레임워크의 우수한 구현의 형태임

MapReduce Programming Model -> 함수형 프로그래밍 언어의 형태
유저는 아래 3가지 함수를 구현해서 제공해야함
Main 함수
Map 함수 : (key1, val1) -> [(key2, val2)]
Reduce 함수 : (key2, [val2]) -> [(key3, val3)]

맵리듀스 프레임워크에서는 각각의 레크드 또는 튜플은 키-밸류 쌍으로 표현된다.

맵리듀스 페이즈는 3단계로 수행되는데,

1. 맵 페이즈는 제일 먼저 수행되며 데이터의 여러 파티션에 병렬 분산으로 호출되어 수행된다.
   각 머신마다 수행된 mapper는 맵 함수가 입력 데이터릐 한 줄 마다 맵 함수를 호출한다.
2. 셔플링 페이즈는 모든 머신에서 맵 페이즈가 다 끝나면 시작된다.
   맵 페이즈에서 각각의 머신으로 보내진 key, value 쌍을 key 를 이용해서 sorting 한 후 에 각각의 key마다 같은 key를 가진 key, value 쌍을 모아서 밸류리스트를 만든 다음에 key, value-list 형태로 key에 따라서 여러 머신에 분산해서 보낸다.
3. 리듀스페이즈 에서는 셔플링 페이즈가 다 끝나면 각 머신마다 리듀스 페이즈가 시작되는데 각각의 머신에서는 셔플링 페이즈에서 해당 머신으로 보내진 각각의 쌍 마다 리듀스 함수가 호출되며 하나의 리듀스 함수가 끝나면 다음 쌍에 리듀스 함수가 호출된다.
   출력이 있다면 key, value 쌍의 형태로 출력된다.

각각의 document에서 mapper로 key value를 만든 다음에 (중복된 key) 특정 조건에 따라서 각각을 머신으로 보내고 (반드시 동일한 키는 동일한 머신으로 ) sorting 한다. 이후에 셔플링 페이즈에서 key값에 따라서 value 를 리스트로 만든다 (각각의 머신마다 발생) 리듀스 페이즈에서 동일한 key 의 value list를 값으로 만든다.

하둡 분산 파일 시스템(Hadoop Distributed File System - HDFS)

- 빅 데이터 파일을 여러 대의 컴퓨터에 나누어서 저장함
- 각 파일은 여러 개의 순차적인 블록으로 저장함
- 하나의 파일의 각각의 블록은 폴트 톨러런스(fault tolerance)를 위해서 여러 개로 복사되어 여러 머신의 여기저기 저장됨
  폴트 톨러런스는 시스템을 구성하는 부품의 일부에서 결함 또는 고장이 발생하여도 정상적 혹은 부분적으로 기능을 수행할 수 있는 것을 말함

#### Combine 함수

Map 함수의 결과 크기를 줄여준다. -> 셔플링 비용을 줄여준다.
각각의 머신에서 map의 결과를 combine 해서 key 에 따른 value값을 미리 합쳐주고 셔플링으로 보낸다.

---

#### Map함수

org.apache.hadoop.mapreduce라는 패키지에 있는 Mapper 클래스를 상속받아서 맵 메소드를 수정한다.

```
public static class TokenizerMapper
			extends Mapper<Object,Text,Text,IntWritable> {

		// variable declairations
		private final static IntWritable one = new IntWritable(1);
		private Text word = new Text();

		// map function (Context -> fixed parameter)
		public void map(Object key, Text value, Context context)
				throws IOException, InterruptedException {

			// value.toString() : get a line
			StringTokenizer itr = new StringTokenizer(value.toString());
			while ( itr.hasMoreTokens() ) {
				word.set(itr.nextToken());

				// emit a key-value pair
				context.write(word,one);
			}
		}
	}

```

여기서 Object key에는 입력 텍스트 파일에서 맨 앞 문자를 기준으로 맵 함수가 호출된 해당 라인의 첫 번째 문자까지의 오프셋(매 라인마다 map이 호출된다고 했는데 그런 호출라인의 정보)
Text value에는 텍스트 해당 라인 전체가 들어있다.

#### Reduce함수

org.apache.hadoop.mapreduce라는 패키지에 있는 Reducer 클래스를 상속받아서 reduce 메소드를 수정한다.

```
public static class IntSumReducer
			extends Reducer<Text,IntWritable,Text,IntWritable> {

		// variables
		private IntWritable result = new IntWritable();

		// key : a disticnt word
		// values :  Iterable type (data list)
		public void reduce(Text key, Iterable<IntWritable> values, Context context)
				throws IOException, InterruptedException {

			int sum = 0;
			for ( IntWritable val : values ) {
				sum += val.get();
			}
			result.set(sum);
			context.write(key,result);
		}
	}

```

셔플링 페이즈의 출력을 입력으로 받는데 key, value-list 형태 -> Text key , Iterable<IntWritable> values
value-list는 맵 함수의 출력에서 key를 갖는 key,value 쌍들의 value들의 리스트
